# VRCMeow 配置文件示例
# 将此文件复制为 config.yaml 并根据您的需求进行修改。
# 注释以 '#' 开头。

# -----------------------------------------------------------------------------
# Dashscope (阿里云灵积) 服务设置
# -----------------------------------------------------------------------------
dashscope:
  # API 密钥 (必需)
  # 强烈建议通过环境变量 `DASHSCOPE_API_KEY` 设置。
  # 如果在此处设置，它将被使用，但环境变量具有更高的优先级。
  api_key: ""

  # --- 语音转文本 (STT) / 语音翻译 (STT+Translation) 设置 ---
  stt:
    # 翻译的目标语言 (可选)
    # 如果设置了有效的语言代码 (例如 "en", "ja", "ko")，将启用翻译功能。
    # 将此值留空 (`""`) 或设置为 `null` 以禁用翻译，仅执行语音识别。
    # 注意：请确保所选的 `selected_model` 支持您指定的目标语言。
    translation_target_language: "" # 示例: "en" (翻译为英语), "" (禁用翻译)

    # 选择要使用的 Dashscope STT 模型 (必需)
    # 此处的值必须是下面 `models` 字典中的一个键。
    selected_model: "gummy-realtime-v1"

    # 定义可用的 Dashscope STT 模型及其配置 (必需)
    # 每个模型的键是模型的名称，值是一个包含其属性的字典。
    # - `sample_rate` (必需): 模型所需的音频采样率 (Hz)。
    # - `supports_translation` (必需): 模型是否支持翻译功能。
    # - `type` (必需): 模型的类型，用于选择正确的识别器实现 ("gummy" 或 "paraformer")。
    models:
      gummy-chat-v1:
        type: "gummy"
        sample_rate: 16000
        supports_translation: true
      gummy-realtime-v1:
        type: "gummy"
        sample_rate: 16000
        supports_translation: true
      paraformer-realtime-v2:
        type: "paraformer"
        sample_rate: 16000
        supports_translation: false
      paraformer-realtime-8k-v2: # 新增: Paraformer 8kHz 模型
        type: "paraformer"
        sample_rate: 8000
        supports_translation: false
      paraformer-mtl-v1: # 新增: Paraformer 多任务模型 (实时 API 通常仅识别)
        type: "paraformer"
        sample_rate: 16000
        supports_translation: false

    # 中间结果处理方式 (可选, 仅影响 VRChat OSC 输出)
    # 定义如何处理 STT 引擎返回的非最终识别结果 (如果模型支持)。
    # - "ignore": (默认) 忽略中间结果，仅发送最终识别/翻译文本。
    # - "show_typing": 在 VRChat 中显示 "正在输入..." 状态。
    # - "show_partial": 在 VRChat 中显示部分识别的文本。
    intermediate_result_behavior: "ignore"

# -----------------------------------------------------------------------------
# 音频输入设置
# -----------------------------------------------------------------------------
audio:
  # 音频输入设备名称 (可选)
  # 指定要使用的麦克风设备名称。您可以在应用程序的仪表盘选项卡中找到可用设备列表。
  # 设置为 "Default" (或留空/null) 以使用系统的默认输入设备。
  # device: "Default" # 取消注释并替换为您的设备名称，例如 "麦克风 (Realtek High Definition Audio)"

  # 音频通道数 (可选)
  # Dashscope 模型通常需要单声道 (1)。
  channels: 1

  # 音频数据类型 (可选)
  # Dashscope Gummy 模型通常需要 'int16'。
  dtype: "int16"

  # 调试回声模式 (可选)
  # 设置为 `true` 以将麦克风输入直接路由到扬声器输出。
  # 这对于在不涉及 STT 或 OSC 的情况下测试麦克风输入是否正常工作很有用。
  # 警告：启用此模式可能会产生啸叫，请谨慎使用并调低音量。
  debug_echo_mode: false

# -----------------------------------------------------------------------------
# 大型语言模型 (LLM) 处理设置
# -----------------------------------------------------------------------------
llm:
  # 是否启用 LLM 处理 (必需)
  # 设置为 `true` 以在 STT 识别/翻译后，使用 LLM 对文本进行进一步处理 (例如, 风格转换、总结等)。
  # 设置为 `false` 以禁用 LLM 处理。
  enabled: false

  # OpenAI 兼容 API 密钥 (必需, 如果 enabled 为 true)
  # 强烈建议通过环境变量 `OPENAI_API_KEY` 设置。
  # 如果在此处设置，它将被使用，但环境变量具有更高的优先级。
  api_key: ""

  # API 基础 URL (可选)
  # 指定 OpenAI 兼容 API 的端点 URL。
  # - 对于 OpenAI 官方 API，通常不需要设置 (默认为 `https://api.openai.com/v1`)。
  # - 对于本地运行的 LLM (例如, 使用 Ollama 并启用 OpenAI 兼容接口): "http://localhost:11434/v1"
  # - 对于 API 代理服务 (例如 Cloudflare AI Gateway, One API 等): 请查阅相应服务的文档。
  # 示例: base_url: "https://gateway.ai.cloudflare.com/v1/..."
  # 示例: base_url: "https://api.example-proxy.com/v1"
  base_url: null

  # 使用的 LLM 模型名称 (必需, 如果 enabled 为 true)
  # 指定要用于处理文本的模型。
  # 示例: "gpt-3.5-turbo", "gpt-4", "gpt-4o", "claude-3-opus-20240229" (取决于您的 API 服务提供商)
  # 对于本地模型 (如 Ollama): "llama3", "qwen:7b" (取决于您已下载并运行的模型)
  model: "gpt-3.5-turbo"

  # 系统提示 (必需, 如果 enabled 为 true)
  # 指导 LLM 如何处理用户输入的指令。
  # 您可以在这里定义 LLM 的角色、任务、输出格式要求等。
  # 下面是一个将文本转换为特定风格的示例：
  system_prompt: |
    你是一名专业的文本风格转换助理。请将用户提供的文本转换为轻松愉快的、略带俏皮的口语风格，类似于和朋友聊天。
    规则：
    1. 保持原始文本的核心含义不变。
    2. 使用更口语化的词语和表达方式。
    3. 可以在句末适当添加一些语气词，如“呀”、“啦”、“哦”。
    4. 避免过于正式或书面化的语言。
    5. 直接输出转换后的文本，不要包含任何解释或标签。

  # 温度 (可选)
  # 控制 LLM 输出的随机性。较低的值 (例如 0.2) 使输出更具确定性和一致性，
  # 较高的值 (例如 1.0) 使输出更具创造性和多样性。
  # 有效范围通常是 0.0 到 2.0。
  temperature: 0.7

  # 最大 Token 数 (可选)
  # 限制 LLM 生成响应的最大长度 (以 token 为单位，大致可以理解为单词或音节)。
  # 这有助于控制 API 成本和响应时间。
  max_tokens: 1024

  # Few-shot 示例 (可选)
  # 提供一些输入/输出示例，以更精确地指导 LLM 的行为，尤其是在执行特定格式转换或风格模仿时。
  # 这是一个包含字典的列表，每个字典代表一个示例，包含 'user' (输入) 和 'assistant' (期望输出)。
  few_shot_examples:
    - user: "今天天气真不错。"
      assistant: "今天天气真好呀！"
    - user: "我需要完成这项工作。"
      assistant: "我得把这活儿干完啦。"
    # - user: "输入示例 3"
    #   assistant: "期望输出 3"

# -----------------------------------------------------------------------------
# 输出目标设置
# -----------------------------------------------------------------------------
outputs:
  # --- VRChat OSC 输出 ---
  vrc_osc:
    # 是否启用 VRChat OSC 输出 (必需)
    # 设置为 `true` 以将最终处理后的文本通过 OSC 发送到 VRChat 聊天框。
    enabled: true

    # VRChat 客户端 IP 地址 (必需)
    # 通常是运行 VRChat 的计算机的 IP 地址。对于本地运行，通常是 "127.0.0.1"。
    address: "127.0.0.1"

    # VRChat OSC 输入端口 (必需)
    # VRChat 默认的 OSC 输入端口是 9000。
    port: 9000

    # 消息发送最小间隔 (秒) (可选)
    # 控制发送到 VRChat 聊天框的消息之间的最短时间间隔。
    # 设置过低 (例如 < 1.333 秒) 可能导致 VRChat 的速率限制或聊天框消息泛滥。
    # 建议值: 1.333 或更高。
    message_interval: 1.333

    # 消息格式字符串 (可选)
    # 定义发送到 VRChat 聊天框的消息格式。
    # `{text}` 将被替换为最终识别/处理后的文本。
    # 示例:
    # "{text}"          (直接发送文本)
    # ">> {text}"       (在文本前添加 ">> ")
    # "Meow: {text}"    (在文本前添加 "Meow: ")
    # "\t{text}\t"     (在文本前后添加制表符，可能影响显示效果)
    format: "{text}" # 默认直接发送文本

    # 是否立即发送 (可选)
    # - `true`: (默认) 消息将直接显示在聊天框中。
    # - `false`: 消息将填充到聊天框的输入栏中，需要手动按 Enter 发送。
    send_immediately: true

    # 是否播放通知音 (可选)
    # 仅当 `send_immediately` 为 `true` 时生效。
    # - `true`: (默认) VRChat 在收到消息时会播放提示音。
    # - `false`: VRChat 不会播放提示音。
    play_notification_sound: true

  # --- 控制台输出 ---
  console:
    # 是否启用控制台输出 (必需)
    # 设置为 `true` 以将最终处理后的文本打印到运行 VRCMeow 的控制台窗口。
    enabled: true # 建议保持启用以进行调试

    # 输出前缀 (可选)
    # 在打印到控制台的每行文本前添加指定的前缀。
    prefix: "[VRCMeow Output]"

  # --- 文件输出 ---
  file:
    # 是否启用文件输出 (必需)
    # 设置为 `true` 以将最终处理后的文本追加到指定的文件中。
    enabled: false

    # 输出文件路径 (必需, 如果 enabled 为 true)
    # 指定用于记录输出文本的文件路径。可以使用相对路径或绝对路径。
    path: "vrcmeow_output.log"

    # 文件记录格式字符串 (可选)
    # 定义写入文件的每行内容的格式。
    # 可用占位符:
    # - `{timestamp}`: 记录时的日期和时间 (例如 "YYYY-MM-DD HH:MM:SS")
    # - `{text}`: 最终识别/处理后的文本
    # 示例:
    # "{timestamp} | {text}"
    # "[{timestamp}] {text}"
    format: "{timestamp} - {text}"

# -----------------------------------------------------------------------------
# 日志记录设置
# -----------------------------------------------------------------------------
logging:
  # 控制台和文件日志的级别 (必需)
  # 决定记录哪些级别的日志消息。级别从低到高： DEBUG < INFO < WARNING < ERROR < CRITICAL
  # - "DEBUG": 最详细的日志，用于诊断问题。
  # - "INFO": (默认) 提供程序运行状态的一般信息。
  # - "WARNING": 指示可能出现的问题或不期望的情况。
  # - "ERROR": 发生了错误，但程序可能仍能继续运行。
  # - "CRITICAL": 严重错误，可能导致程序终止。
  level: "INFO"

  # --- 应用程序日志文件设置 -
  file:
    # 是否启用应用程序日志文件 (必需)
    # 设置为 `true` 以将详细的应用程序运行日志 (包括 DEBUG, INFO, WARNING, ERROR, CRITICAL 消息)
    # 写入到指定的文件中。这对于问题排查非常有用。
    # 注意：这与 `outputs.file` 不同，后者仅记录最终的 STT/LLM 结果文本。
    enabled: false

    # 应用程序日志文件路径 (必需, 如果 enabled 为 true)
    # 指定保存应用程序运行日志的文件路径。
    path: "vrcmeow_app.log"
