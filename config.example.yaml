# VRCMeow Configuration Example
# Copy this file to config.yaml and modify it according to your needs.
# Comments start with '#'.

# -----------------------------------------------------------------------------
# Dashscope (Alibaba Cloud Lingji) Service Settings
# -----------------------------------------------------------------------------
dashscope:
  # API Key (Required)
  # Strongly recommended to set via the `DASHSCOPE_API_KEY` environment variable.
  # If set here, it will be used, but the environment variable takes higher priority.
  api_key: ""

  # --- Speech-to-Text (STT) / Speech Translation (STT+Translation) Settings ---
  stt:
    # Target language for translation (Optional)
    # If a valid language code is set (e.g., "en", "ja", "ko"), translation will be enabled.
    # Leave this value empty (`""`) or set it to `null` to disable translation and perform only speech recognition.
    # Note: Ensure the selected `model` supports the target language you specify.
    translation_target_language: "" # Example: "en" (Translate to English), "" (Disable translation)

    # Dashscope model to use (Required)
    # - "gummy-realtime-v1": Supports real-time speech recognition and translation.
    # - "paraformer-realtime-v2", "paraformer-realtime-v1": Supports only real-time speech recognition.
    # Please consult the Dashscope documentation for the latest model list and features.
    model: "gummy-realtime-v1"

    # Intermediate result handling (Optional, affects VRChat OSC output only)
    # Defines how to handle non-final recognition results returned by the STT engine.
    # - "ignore": (Default) Ignores intermediate results, only sends the final recognized/translated text.
    # - "show_typing": Displays "Typing..." status in VRChat.
    # - "show_partial": Displays partially recognized text in VRChat.
    intermediate_result_behavior: "ignore"

# -----------------------------------------------------------------------------
# Audio Input Settings
# -----------------------------------------------------------------------------
audio:
  # Audio input device name (Optional)
  # Specify the name of the microphone device to use. You can find available devices in the application's dashboard tab.
  # Set to "Default" (or leave empty/null) to use the system's default input device.
  # device: "Default" # Uncomment and replace with your device name, e.g., "Microphone (Realtek High Definition Audio)"

  # Audio sample rate (Hz) (Optional)
  # Set to `null` (or leave empty) to attempt auto-detection and use the default input device's sample rate.
  # If auto-detection fails, or if you uncomment this line and set a specific value, the specified value will be used.
  # Default fallback value: 16000 Hz.
  # Note: Ensure the sample rate is compatible with the selected Dashscope STT model (e.g., Gummy models usually require 16000 Hz).
  sample_rate: null # Example: 16000

  # Number of audio channels (Optional)
  # Dashscope Gummy models usually require mono (1).
  channels: 1

  # Audio data type (Optional)
  # Dashscope Gummy models usually require 'int16'.
  dtype: "int16"

  # Debug echo mode (Optional)
  # Set to `true` to route microphone input directly to speaker output.
  # Useful for testing if microphone input is working correctly without involving STT or OSC.
  # Warning: Enabling this mode may cause feedback (howling). Use with caution and lower your volume.
  debug_echo_mode: false

# -----------------------------------------------------------------------------
# Large Language Model (LLM) Processing Settings
# -----------------------------------------------------------------------------
llm:
  # Enable LLM processing (Required)
  # Set to `true` to use an LLM for further processing of the text after STT recognition/translation (e.g., style conversion, summarization).
  # Set to `false` to disable LLM processing.
  enabled: false

  # OpenAI compatible API Key (Required if enabled is true)
  # Strongly recommended to set via the `OPENAI_API_KEY` environment variable.
  # If set here, it will be used, but the environment variable takes higher priority.
  api_key: ""

  # API Base URL (Optional)
  # Specify the endpoint URL for the OpenAI compatible API.
  # - For the official OpenAI API, usually not needed (defaults to `https://api.openai.com/v1`).
  # - For locally running LLMs (e.g., using Ollama with OpenAI compatible interface enabled): "http://localhost:11434/v1"
  # - For API proxy services (e.g., Cloudflare AI Gateway, One API, etc.): Consult the respective service's documentation.
  # Example: base_url: "https://gateway.ai.cloudflare.com/v1/..."
  # Example: base_url: "https://api.example-proxy.com/v1"
  base_url: null

  # LLM model name to use (Required if enabled is true)
  # Specify the model to use for text processing.
  # Example: "gpt-3.5-turbo", "gpt-4", "gpt-4o", "claude-3-opus-20240229" (depends on your API service provider)
  # For local models (like Ollama): "llama3", "qwen:7b" (depends on the models you have downloaded and are running)
  model: "gpt-3.5-turbo"

  # System prompt (Required if enabled is true)
  # Instructions that guide the LLM on how to process the user input.
  # You can define the LLM's role, task, output format requirements, etc., here.
  # Below is an example for converting text to a specific style:
  system_prompt: |
    You are a professional text style conversion assistant. Please convert the text provided by the user into a relaxed, slightly playful, conversational style, similar to chatting with a friend.
    Rules:
    1. Keep the core meaning of the original text unchanged.
    2. Use more colloquial words and expressions.
    3. You can appropriately add some particles like "ya", "la", "oh" at the end of sentences.
    4. Avoid overly formal or written language.
    5. Directly output the converted text without any explanation or labels.

  # Temperature (Optional)
  # Controls the randomness of the LLM's output. Lower values (e.g., 0.2) make the output more deterministic and consistent,
  # higher values (e.g., 1.0) make it more creative and diverse.
  # Valid range is typically 0.0 to 2.0.
  temperature: 0.7

  # Max Tokens (Optional)
  # Limits the maximum length of the LLM's generated response (in tokens, roughly corresponding to words or syllables).
  # Helps control API costs and response time.
  max_tokens: 256

  # Few-shot examples (Optional)
  # Provide some input/output examples to guide the LLM's behavior more precisely, especially when performing specific format conversions or style imitations.
  # This is a list of dictionaries, each representing an example with 'user' (input) and 'assistant' (expected output).
  few_shot_examples:
    - user: "The weather is really nice today."
      assistant: "Wow, the weather's great today!"
    - user: "I need to finish this work."
      assistant: "Gotta get this work done."
    # - user: "Input Example 3"
    #   assistant: "Expected Output 3"

# -----------------------------------------------------------------------------
# Output Destination Settings
# -----------------------------------------------------------------------------
outputs:
  # --- VRChat OSC Output ---
  vrc_osc:
    # Enable VRChat OSC output (Required)
    # Set to `true` to send the final processed text via OSC to the VRChat chatbox.
    enabled: true

    # VRChat client IP address (Required)
    # Usually the IP address of the computer running VRChat. For local runs, typically "127.0.0.1".
    address: "127.0.0.1"

    # VRChat OSC input port (Required)
    # VRChat's default OSC input port is 9000.
    port: 9000

    # Minimum message sending interval (seconds) (Optional)
    # Controls the shortest time interval between messages sent to the VRChat chatbox.
    # Setting too low (e.g., < 1.333 seconds) may lead to VRChat rate limiting or chatbox message flooding.
    # Recommended value: 1.333 or higher.
    message_interval: 1.333

    # Message format string (Optional)
    # Defines the format of the message sent to the VRChat chatbox.
    # `{text}` will be replaced with the final recognized/processed text.
    # Examples:
    # "{text}"          (Send text directly)
    # ">> {text}"       (Add ">> " before the text)
    # "Meow: {text}"    (Add "Meow: " before the text)
    # "\t{text}\t"     (Add tabs around the text, may affect display)
    format: "{text}" # Default: send text directly

    # Send immediately (Optional)
    # - `true`: (Default) The message will be displayed directly in the chatbox.
    # - `false`: The message will populate the chatbox input field, requiring manual Enter press to send.
    send_immediately: true

    # Play notification sound (Optional)
    # Only effective when `send_immediately` is `true`.
    # - `true`: (Default) VRChat will play a notification sound upon receiving the message.
    # - `false`: VRChat will not play a notification sound.
    play_notification_sound: true

  # --- Console Output ---
  console:
    # Enable console output (Required)
    # Set to `true` to print the final processed text to the console window running VRCMeow.
    enabled: true # Recommended to keep enabled for debugging

    # Output prefix (Optional)
    # Adds the specified prefix before each line of text printed to the console.
    prefix: "[VRCMeow Output]"

  # --- File Output ---
  file:
    # Enable file output (Required)
    # Set to `true` to append the final processed text to the specified file.
    enabled: false

    # Output file path (Required if enabled is true)
    # Specify the file path for logging the output text. Can use relative or absolute paths.
    path: "vrcmeow_output.log"

    # File record format string (Optional)
    # Defines the format for each line written to the file.
    # Available placeholders:
    # - `{timestamp}`: Date and time of recording (e.g., "YYYY-MM-DD HH:MM:SS")
    # - `{text}`: Final recognized/processed text
    # Examples:
    # "{timestamp} | {text}"
    # "[{timestamp}] {text}"
    format: "{timestamp} - {text}"

# -----------------------------------------------------------------------------
# Logging Settings
# -----------------------------------------------------------------------------
logging:
  # Level for console and file logs (Required)
  # Determines which levels of log messages are recorded. Levels from lowest to highest: DEBUG < INFO < WARNING < ERROR < CRITICAL
  # - "DEBUG": Most detailed logs, for diagnosing problems.
  # - "INFO": (Default) Provides general information about the program's running state.
  # - "WARNING": Indicates potential issues or unexpected situations.
  # - "ERROR": An error occurred, but the program might still be able to continue running.
  # - "CRITICAL": Severe error, potentially causing the program to terminate.
  level: "INFO"

  # --- Application Log File Settings ---
  file:
    # Enable application log file (Required)
    # Set to `true` to write detailed application runtime logs (including DEBUG, INFO, WARNING, ERROR, CRITICAL messages)
    # to the specified file. Very useful for troubleshooting.
    # Note: This is different from `outputs.file`, which only logs the final STT/LLM result text.
    enabled: true

    # Application log file path (Required if enabled is true)
    # Specify the file path to save the application runtime logs.
    path: "vrcmeow_app.log"
